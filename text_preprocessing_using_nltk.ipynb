{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text pre-processing using NLTK\n",
    "\n",
    "In this notebook I work through the Implementing Text Pre-processing Using NLTK exercise from the [intro to NLP course by Shivam Bansal](https://courses.analyticsvidhya.com/courses/Intro-to-NLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/pdrew/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/pdrew/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/pdrew/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dowload some packages we will need later\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Last night Oliver was sick. He walked around the bedroom a lot and tried to get our attention\\\n",
    "        but I was asleep and Lina did not understand he was feeling sick because he was not displaying\\\n",
    "        his usual tells.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n sentences: 2 \n",
      "\n",
      "sentence 0 : Last night Oliver was sick.\n",
      "sentence 1 : He walked around the bedroom a lot and tried to get our attention        but I was asleep and Lina did not understand he was feeling sick because he was not displaying        his usual tells.\n"
     ]
    }
   ],
   "source": [
    "# separate out the sentences\n",
    "sents = nltk.tokenize.sent_tokenize(text)\n",
    "\n",
    "print('n sentences:', len(sents), '\\n')\n",
    "\n",
    "for i in range(len(sents)):\n",
    "    print('sentence', str(i), \":\", sents[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first 10 words are: ['Last', 'night', 'Oliver', 'was', 'sick', '.', 'He', 'walked', 'around', 'the']\n"
     ]
    }
   ],
   "source": [
    "# now let's tokenize words instead of sentences\n",
    "words = nltk.tokenize.word_tokenize(text)\n",
    "\n",
    "print('the first 10 words are:', words[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "Now let's try removing the affixes from words, leaving just the stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Last', 'night', 'Oliver', 'was', 'sick', '.', 'He', 'walked', 'around', 'the', 'bedroom', 'a', 'lot', 'and', 'tried', 'to', 'get', 'our', 'attention', 'but', 'I', 'was', 'asleep', 'and', 'Lina', 'did', 'not', 'understand', 'he', 'was', 'feeling', 'sick', 'because', 'he', 'was', 'not', 'displaying', 'his', 'usual', 'tells', '.']\n"
     ]
    }
   ],
   "source": [
    "# make a stemmer object\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['last', 'night', 'oliv', 'wa', 'sick', '.', 'He', 'walk', 'around', 'the', 'bedroom', 'a', 'lot', 'and', 'tri', 'to', 'get', 'our', 'attent', 'but', 'I', 'wa', 'asleep', 'and', 'lina', 'did', 'not', 'understand', 'he', 'wa', 'feel', 'sick', 'becaus', 'he', 'wa', 'not', 'display', 'hi', 'usual', 'tell', '.']\n"
     ]
    }
   ],
   "source": [
    "# let's try stemming each of the words from the story above\n",
    "\n",
    "# singles = [stemmer.stem(words) for word in words]\n",
    "\n",
    "singles = words.copy()\n",
    "for i in range(len(words)):\n",
    "    singles[i] = stemmer.stem(words[i])\n",
    "    \n",
    "print(singles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that some of these stemmed words are no longer words in the dictionary, for example oliver became oliv and was became wa. For this reason stemming is not a good tool for the normalization of text. Lemmatizing is a better choice than stemming for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Last', 'night', 'Oliver', 'wa', 'sick', '.', 'He', 'walked', 'around', 'the', 'bedroom', 'a', 'lot', 'and', 'tried', 'to', 'get', 'our', 'attention', 'but', 'I', 'wa', 'asleep', 'and', 'Lina', 'did', 'not', 'understand', 'he', 'wa', 'feeling', 'sick', 'because', 'he', 'wa', 'not', 'displaying', 'his', 'usual', 'tell', '.']\n"
     ]
    }
   ],
   "source": [
    "lem = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "singles = words.copy()\n",
    "for i in range(len(words)):\n",
    "    singles[i] = lem.lemmatize(words[i])\n",
    "    \n",
    "print(singles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization did better, but still fails to work on the word 'was'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 10 parts of speech: [('Last', 'JJ'), ('night', 'NN'), ('Oliver', 'NNP'), ('was', 'VBD'), ('sick', 'JJ'), ('.', '.'), ('He', 'PRP'), ('walked', 'VBD'), ('around', 'IN'), ('the', 'DT')]\n"
     ]
    }
   ],
   "source": [
    "# nltk can also be used to categorize the parts of speech for each word in our story.\n",
    "pos = nltk.pos_tag(words)\n",
    "print('first 10 parts of speech:', pos[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model for Text Classification\n",
    "Now let's build a basic ML model for text classification and detection of hate speech from twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dF = pd.read_csv('data/final_dataset_basicmlmodel.csv')\n",
    "dF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe is already organized in such a way as to be used as our output, which is to say, the column titled label is where the classification of hate speech will be stored. The label of 0 implies a classification of no hate speech and 1 implies hate speech. The first step we'll take is to clean the data to reduce the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(text):\n",
    "    # filter to allow only alphameric characters\n",
    "    text = re.sub(r'[^a-zA-Z\\']', ' ', text)\n",
    "    \n",
    "    # Remove Unicode characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    \n",
    "    # enforce lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>user  user thanks for  lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide  society now     motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0    user when a father is dysfunctional and is s...  \n",
       "1   user  user thanks for  lyft credit i can't us...  \n",
       "2                                bihday your majesty  \n",
       "3   model   i love u take with u all the time in ...  \n",
       "4             factsguide  society now     motivation  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dF['clean_tweet'] = dF.tweet.apply(lambda x: clean_tweets(x))\n",
    "\n",
    "dF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
